{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0db956eb77c6256702a2b21b3c227e5d21cf60bdbf418ac52193d82189149c07c",
   "display_name": "Python 3.6.10 64-bit ('learn': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6999, 59)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "5705   1121103       0          1              1          4              1   \n",
       "23952   930830       0          3              4          9              0   \n",
       "10345   123596       0          4              1          6              0   \n",
       "74920    72801       0          0              2          0              0   \n",
       "98696   854474       0          4              2          1              0   \n",
       "61797  1073965       0          2              2          2              1   \n",
       "56152   460902       0          5              1          4              0   \n",
       "60957   692878       0          1              3          3              0   \n",
       "66691  1282475       0          0              1          6              0   \n",
       "22508  1136075       0          1              1          2              0   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "5705               0              0              0              1  ...   \n",
       "23952              0              0              0              1  ...   \n",
       "10345              4              1              0              0  ...   \n",
       "74920              0              0              1              0  ...   \n",
       "98696              0              1              0              0  ...   \n",
       "61797              0              0              0              0  ...   \n",
       "56152              0              0              0              0  ...   \n",
       "60957              0              0              0              0  ...   \n",
       "66691              0              0              1              0  ...   \n",
       "22508              0              0              0              0  ...   \n",
       "\n",
       "       ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "5705            2           2           0           4               0   \n",
       "23952           5           0           4          12               0   \n",
       "10345           7           1           5           3               0   \n",
       "74920           3           3           2           7               0   \n",
       "98696           5           4           2          10               0   \n",
       "61797           3           1           0           4               1   \n",
       "56152           4           2           1           6               0   \n",
       "60957           3           2           6           8               0   \n",
       "66691          10           2           2           9               0   \n",
       "22508           3           2           2          12               0   \n",
       "\n",
       "       ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "5705                1               0               1               0   \n",
       "23952               1               0               1               0   \n",
       "10345               0               0               0               0   \n",
       "74920               0               1               1               0   \n",
       "98696               1               1               0               0   \n",
       "61797               1               0               0               1   \n",
       "56152               1               1               0               0   \n",
       "60957               1               0               0               0   \n",
       "66691               1               0               0               0   \n",
       "22508               1               0               1               1   \n",
       "\n",
       "       ps_calc_20_bin  \n",
       "5705                0  \n",
       "23952               0  \n",
       "10345               0  \n",
       "74920               0  \n",
       "98696               0  \n",
       "61797               0  \n",
       "56152               1  \n",
       "60957               0  \n",
       "66691               0  \n",
       "22508               0  \n",
       "\n",
       "[10 rows x 59 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>ps_ind_01</th>\n      <th>ps_ind_02_cat</th>\n      <th>ps_ind_03</th>\n      <th>ps_ind_04_cat</th>\n      <th>ps_ind_05_cat</th>\n      <th>ps_ind_06_bin</th>\n      <th>ps_ind_07_bin</th>\n      <th>ps_ind_08_bin</th>\n      <th>...</th>\n      <th>ps_calc_11</th>\n      <th>ps_calc_12</th>\n      <th>ps_calc_13</th>\n      <th>ps_calc_14</th>\n      <th>ps_calc_15_bin</th>\n      <th>ps_calc_16_bin</th>\n      <th>ps_calc_17_bin</th>\n      <th>ps_calc_18_bin</th>\n      <th>ps_calc_19_bin</th>\n      <th>ps_calc_20_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5705</th>\n      <td>1121103</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23952</th>\n      <td>930830</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10345</th>\n      <td>123596</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74920</th>\n      <td>72801</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98696</th>\n      <td>854474</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61797</th>\n      <td>1073965</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56152</th>\n      <td>460902</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>60957</th>\n      <td>692878</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66691</th>\n      <td>1282475</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22508</th>\n      <td>1136075</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 59 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.read_csv('data/car.csv')\n",
    "df_1 = df[df['target']==1]\n",
    "df_0 = df[df['target']==0].sample(n=len(df_1))\n",
    "df = pd.concat([df_0,df_1],axis=0)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "NUMERIC_COLS = [\n",
    "    \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "    \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\",\n",
    "]\n",
    "print(df_train.shape)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']  # training label\n",
    "y_test = df_test['target']  # training label\n",
    "X_train = df_train[NUMERIC_COLS]  # training dataset\n",
    "X_test = df_test[NUMERIC_COLS]  # testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start training...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\ttraining's binary_logloss: 0.692401\n",
      "[2]\ttraining's binary_logloss: 0.691612\n",
      "[3]\ttraining's binary_logloss: 0.690827\n",
      "[4]\ttraining's binary_logloss: 0.69007\n",
      "[5]\ttraining's binary_logloss: 0.689337\n",
      "[6]\ttraining's binary_logloss: 0.688705\n",
      "[7]\ttraining's binary_logloss: 0.687967\n",
      "[8]\ttraining's binary_logloss: 0.687355\n",
      "[9]\ttraining's binary_logloss: 0.686629\n",
      "[10]\ttraining's binary_logloss: 0.68591\n",
      "[11]\ttraining's binary_logloss: 0.685201\n",
      "[12]\ttraining's binary_logloss: 0.684508\n",
      "[13]\ttraining's binary_logloss: 0.68382\n",
      "[14]\ttraining's binary_logloss: 0.683114\n",
      "[15]\ttraining's binary_logloss: 0.682437\n",
      "[16]\ttraining's binary_logloss: 0.681817\n",
      "[17]\ttraining's binary_logloss: 0.681197\n",
      "[18]\ttraining's binary_logloss: 0.680594\n",
      "[19]\ttraining's binary_logloss: 0.679979\n",
      "[20]\ttraining's binary_logloss: 0.679369\n",
      "[21]\ttraining's binary_logloss: 0.678734\n",
      "[22]\ttraining's binary_logloss: 0.678072\n",
      "[23]\ttraining's binary_logloss: 0.677447\n",
      "[24]\ttraining's binary_logloss: 0.676832\n",
      "[25]\ttraining's binary_logloss: 0.676172\n",
      "[26]\ttraining's binary_logloss: 0.67554\n",
      "[27]\ttraining's binary_logloss: 0.674981\n",
      "[28]\ttraining's binary_logloss: 0.674441\n",
      "[29]\ttraining's binary_logloss: 0.673849\n",
      "[30]\ttraining's binary_logloss: 0.673217\n",
      "[31]\ttraining's binary_logloss: 0.672637\n",
      "[32]\ttraining's binary_logloss: 0.672064\n",
      "[33]\ttraining's binary_logloss: 0.67152\n",
      "[34]\ttraining's binary_logloss: 0.670974\n",
      "[35]\ttraining's binary_logloss: 0.6704\n",
      "[36]\ttraining's binary_logloss: 0.6698\n",
      "[37]\ttraining's binary_logloss: 0.669272\n",
      "[38]\ttraining's binary_logloss: 0.66869\n",
      "[39]\ttraining's binary_logloss: 0.668162\n",
      "[40]\ttraining's binary_logloss: 0.667588\n",
      "[41]\ttraining's binary_logloss: 0.667028\n",
      "[42]\ttraining's binary_logloss: 0.66646\n",
      "[43]\ttraining's binary_logloss: 0.665974\n",
      "[44]\ttraining's binary_logloss: 0.665401\n",
      "[45]\ttraining's binary_logloss: 0.66487\n",
      "[46]\ttraining's binary_logloss: 0.664347\n",
      "[47]\ttraining's binary_logloss: 0.663793\n",
      "[48]\ttraining's binary_logloss: 0.663251\n",
      "[49]\ttraining's binary_logloss: 0.662721\n",
      "[50]\ttraining's binary_logloss: 0.662181\n",
      "[51]\ttraining's binary_logloss: 0.661754\n",
      "[52]\ttraining's binary_logloss: 0.661296\n",
      "[53]\ttraining's binary_logloss: 0.660848\n",
      "[54]\ttraining's binary_logloss: 0.660411\n",
      "[55]\ttraining's binary_logloss: 0.659901\n",
      "[56]\ttraining's binary_logloss: 0.659392\n",
      "[57]\ttraining's binary_logloss: 0.658904\n",
      "[58]\ttraining's binary_logloss: 0.658419\n",
      "[59]\ttraining's binary_logloss: 0.65796\n",
      "[60]\ttraining's binary_logloss: 0.657433\n",
      "[61]\ttraining's binary_logloss: 0.656947\n",
      "[62]\ttraining's binary_logloss: 0.656465\n",
      "[63]\ttraining's binary_logloss: 0.656032\n",
      "[64]\ttraining's binary_logloss: 0.655577\n",
      "[65]\ttraining's binary_logloss: 0.655138\n",
      "[66]\ttraining's binary_logloss: 0.654687\n",
      "[67]\ttraining's binary_logloss: 0.654236\n",
      "[68]\ttraining's binary_logloss: 0.653805\n",
      "[69]\ttraining's binary_logloss: 0.653391\n",
      "[70]\ttraining's binary_logloss: 0.652959\n",
      "[71]\ttraining's binary_logloss: 0.652476\n",
      "[72]\ttraining's binary_logloss: 0.652017\n",
      "[73]\ttraining's binary_logloss: 0.651591\n",
      "[74]\ttraining's binary_logloss: 0.651192\n",
      "[75]\ttraining's binary_logloss: 0.650755\n",
      "[76]\ttraining's binary_logloss: 0.650339\n",
      "[77]\ttraining's binary_logloss: 0.649935\n",
      "[78]\ttraining's binary_logloss: 0.649478\n",
      "[79]\ttraining's binary_logloss: 0.649075\n",
      "[80]\ttraining's binary_logloss: 0.64868\n",
      "[81]\ttraining's binary_logloss: 0.648204\n",
      "[82]\ttraining's binary_logloss: 0.647779\n",
      "[83]\ttraining's binary_logloss: 0.647302\n",
      "[84]\ttraining's binary_logloss: 0.646958\n",
      "[85]\ttraining's binary_logloss: 0.646495\n",
      "[86]\ttraining's binary_logloss: 0.646102\n",
      "[87]\ttraining's binary_logloss: 0.645688\n",
      "[88]\ttraining's binary_logloss: 0.645251\n",
      "[89]\ttraining's binary_logloss: 0.644872\n",
      "[90]\ttraining's binary_logloss: 0.644446\n",
      "[91]\ttraining's binary_logloss: 0.644044\n",
      "/home/wlyu/software/anaconda3/envs/learn/lib/python3.6/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[92]\ttraining's binary_logloss: 0.643575\n",
      "[93]\ttraining's binary_logloss: 0.643117\n",
      "[94]\ttraining's binary_logloss: 0.642669\n",
      "[95]\ttraining's binary_logloss: 0.64227\n",
      "[96]\ttraining's binary_logloss: 0.641914\n",
      "[97]\ttraining's binary_logloss: 0.641501\n",
      "[98]\ttraining's binary_logloss: 0.641086\n",
      "[99]\ttraining's binary_logloss: 0.640739\n",
      "[100]\ttraining's binary_logloss: 0.640342\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb \n",
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_eval = lgb.Dataset(X_test,y_test,reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 64,\n",
    "    \"num_trees\": 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "num_leaf = 64\n",
    "print('start training...')\n",
    "# train GBDT\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Save model...\nStart predicting...\n(6999, 100)\n[43 12 39 12 62 57 48 57 58 35 16 16 16 62 16 60 46 46 50 33  9 17  9 12\n  6 17 57 56 40 33 37 15  1 15 35 44 22  7 22 43 13 51 25 40 62 14 11 54\n 11 32 25 17 17 15 44 17 28 17 48 21  4 58 23 52 35 29 24 23 23 28 37 21\n 17 17 13 30 30  3 30 33 16 27 16 62 15 63 55  6 56 40 12 40 44 44 14 23\n 23 44 26 33]\n"
     ]
    }
   ],
   "source": [
    "print('Save model...')\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "y_pred = gbm.predict(X_train,pred_leaf=True)\n",
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing transformed training data\n"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf],\n",
    "                                       dtype=np.int64)  # N * num_tress * num_leafs\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing transformed testing data\n"
     ]
    }
   ],
   "source": [
    "# 对测试集进行tree的转变\n",
    "y_pred = gbm.predict(X_test, pred_leaf=True)\n",
    "print('Writing transformed testing data')\n",
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_testing_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/wlyu/software/anaconda3/envs/learn/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression(penalty='l2',C=0.05) # logestic model construction\n",
    "lm.fit(transformed_training_matrix,y_train)  # fitting the data\n",
    "y_pred_test = lm.predict_proba(transformed_testing_matrix)   # Give the probabilty on each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.56      0.52      0.54       865\n           1       0.54      0.57      0.55       840\n\n    accuracy                           0.55      1705\n   macro avg       0.55      0.55      0.55      1705\nweighted avg       0.55      0.55      0.55      1705\n\n              precision    recall  f1-score   support\n\n           0       0.58      0.57      0.57       865\n           1       0.56      0.57      0.56       840\n\n    accuracy                           0.57      1705\n   macro avg       0.57      0.57      0.57      1705\nweighted avg       0.57      0.57      0.57      1705\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_test[:,1]>0.5))\n",
    "y_pred = gbm.predict(X_test,pred_leaf=False)\n",
    "print(classification_report(y_test,y_pred>0.5))"
   ]
  }
 ]
}